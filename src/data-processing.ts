/**
 * @module
 * This module provides high-level utilities for parallel data processing. It
 * includes abstractions like `mapReduce`, parallel `filter`, and parallel
 * `groupBy` to operate on collections of data concurrently, leveraging the
 * full power of the underlying scheduler for maximum performance.
 */

import { defineTask, getContext, run, type Task, type BaseContext, type Scope } from './run';

// Import the symbol used to store unctx instance on context objects
const UNCTX_INSTANCE_SYMBOL = Symbol('__unctx_instance__');
import { all, type ParallelOptions } from './scheduler';

interface MapReduceOptions<C extends BaseContext, T, R, U> extends ParallelOptions {
  map: Task<C, T, R>;
  reduce: (accumulator: U, current: R) => U;
  initial: U;
}

/**
 * Performs a parallel map operation over an array of data, followed by a
 * sequential reduce operation to produce a single summary value. This is a
 * classic MapReduce pattern.
 *
 * @param data The array of data to process.
 * @param options The configuration containing the mapping `Task`, the reduce function,
 *                and the initial value for the accumulator. Concurrency options
 *                for the parallel map phase can also be provided.
 * @returns A `Task` that resolves to the final reduced value.
 *
 * @example
 * ```typescript
 * const userIds = ['u-1', 'u-2', 'u-3'];
 * const countUserPosts = pipe(fetchPosts, map(posts => posts.length));
 *
 * const countAllPosts = mapReduce(userIds, {
 *   map: countUserPosts,
 *   reduce: (total, count) => total + count,
 *   initial: 0,
 *   concurrency: 4,
 * });
 *
 * const total = await run(countAllPosts);
 * ```
 */
export function mapReduce<C extends { scope: Scope }, T, R, U>(
  data: T[],
  options: MapReduceOptions<C, T, R, U>
): Task<C, null, U> {
  const { map: mapTask, reduce: reduceFn, initial, ...parallelOptions } = options;

  return async (context: C, _: null): Promise<U> => {
    // 1. Map Phase: Create an executable task for each item in the data array.
    // We need to store the unctx instance to properly execute tasks
    const unctxInstance = (context as any)[UNCTX_INSTANCE_SYMBOL];
    const mapTasks = data.map(item => async () => {
      // Execute the task within the proper unctx context if available
      if (unctxInstance) {
        return unctxInstance.callAsync(context, () => mapTask(context, item));
      } else {
        return mapTask(context, item);
      }
    });

    // Execute all mapping tasks in parallel.
    const mappedResults = await all(mapTasks, null, parallelOptions, context);

    // 2. Reduce Phase: Sequentially apply the reducer to the results.
    return mappedResults.reduce(reduceFn, initial);
  };
}

/**
 * **Pipeable Operator:** Filters an array by applying an async predicate `Task`
 * to each item in parallel.
 *
 * @param predicateTask A `Task` that takes an item and returns a `Promise<boolean>`.
 * @param options Optional concurrency settings for the predicate execution.
 * @returns A `Task` that receives an array and resolves to the new, filtered array.
 *
 * @example
 * ```typescript
 * const filterActiveUsers = pipe(
 *   fetchAllUsers,
 *   filter(userIsActiveTask, { concurrency: 8 }), // userIsActiveTask runs in parallel
 *   map(activeUsers => `Found ${activeUsers.length} active users.`)
 * );
 * ```
 */
export function filter<C extends { scope: Scope }, V>(
  predicateTask: Task<C, V, boolean>,
  options?: ParallelOptions
): Task<C, V[], V[]> {
  return async (context: C, data: V[]): Promise<V[]> => {
    const unctxInstance = (context as any)[UNCTX_INSTANCE_SYMBOL];
    const predicateTasks = data.map(item =>
      async () => {
        // Execute the task within the proper unctx context if available
        if (unctxInstance) {
          return unctxInstance.callAsync(context, () => predicateTask(context, item));
        } else {
          return predicateTask(context, item);
        }
      }
    );

    // Run all predicates in parallel to get a corresponding array of booleans.
    const results = await all(predicateTasks, null, options, context);

    // Filter the original data array based on the boolean results.
    return data.filter((_, index) => results[index]);
  };
}

/**
 * **Pipeable Operator:** Groups items in an array into a `Map` based on a key
 * generated by a `keyingTask` that runs in parallel for each item.
 *
 * @param keyingTask A `Task` that takes an item and returns a `Promise` of its key.
 *                   This can also be a simple synchronous function for simple cases.
 * @param options Optional concurrency settings for the keying task execution.
 * @returns A `Task` that resolves to a `Map` where keys are the generated keys
 *          and values are arrays of items belonging to that key.
 */
export function groupBy<C extends { scope: Scope }, V, K extends string | number | symbol>(
  keyingTask: Task<C, V, K> | ((item: V) => K),
  options?: ParallelOptions
): Task<C, V[], Map<K, V[]>> {
  // Normalize the input to always be a Task for consistent handling.
  const task = typeof keyingTask === 'function' && !(keyingTask as any).__task_id
    ? defineTask(async (item: V) => (keyingTask as ((item: V) => K))(item))
    : (keyingTask as Task<C, V, K>);

  return async (context: C, data: V[]): Promise<Map<K, V[]>> => {
    // Generate all keys in parallel using the scheduler's all function to respect concurrency limits
    const unctxInstance = (context as any)[UNCTX_INSTANCE_SYMBOL];
    const keyTasks = data.map(item => async () => {
      // Execute the task within the proper unctx context if available
      if (unctxInstance) {
        return unctxInstance.callAsync(context, () => task(context, item));
      } else {
        return task(context, item);
      }
    });

    // Execute all keying tasks in parallel with concurrency limits
    const keys = await all(keyTasks, null, options, context);

    // Group items by their corresponding key.
    const groups = new Map<K, V[]>();
    for (let i = 0; i < data.length; i++) {
      const key = keys[i];
      const item = data[i];
      if (!groups.has(key)) {
        groups.set(key, []);
      }
      groups.get(key)!.push(item);
    }

    return groups;
  };
}