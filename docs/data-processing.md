## ðŸ”„ Parallel Data Processing Utilities (`data-processing.ts`)

This module offers high-level abstractions for common data processing patterns on collections, such as mapping, reducing, filtering, and grouping. These operations are performed concurrently by leveraging the powerful scheduling capabilities from the `scheduler.ts` module, allowing for fine-grained control over parallelism and resource usage.

These utilities are designed to integrate seamlessly with your `Task`-based workflows.

### Table of Contents

1.  [Overview](#overview)
2.  [Core Pattern: Adapting for the Scheduler](#core-pattern-adapting-for-the-scheduler)
3.  [API Reference & Usage](#api-reference--usage)
    *   [`mapReduce`](#mapreduce)
    *   [`filter` (Pipeable Operator)](#filter-pipeable-operator)
    *   [`groupBy` (Pipeable Operator)](#groupby-pipeable-operator)
4.  [Key Concepts & How They Work](#key-concepts--how-they-work)
    *   Interaction with `scheduler.all` and `scheduler.allSettled`
    *   Context Handling
    *   Error Propagation
    *   Concurrency and `ParallelOptions`
5.  [Usage Examples](#usage-examples)
    *   Calculating Aggregate Statistics (`mapReduce`)
    *   Filtering a Collection Based on Async Checks (`filter`)
    *   Categorizing Items (`groupBy`)
6.  [Best Practices & Considerations](#best-practices--considerations)
7.  [Troubleshooting](#troubleshooting)


### 1. Overview

When working with collections of data, you often need to apply an operation to each item, filter items based on some criteria, or group them by a common characteristic. Doing these operations sequentially can be slow if the per-item operation involves I/O or significant computation.

This module provides three main utilities:

*   **`mapReduce`**: Applies a mapping `Task` to each item in an array in parallel, then sequentially reduces the results to a single value.
*   **`filter`**: A pipeable operator that filters an array by applying an asynchronous predicate `Task` to each item in parallel.
*   **`groupBy`**: A pipeable operator that groups items from an array into a `Map` based on a key generated by a (potentially asynchronous) `Task` applied to each item in parallel.

All these utilities use the `all` or `allSettled` functions from `scheduler.ts` under the hood to manage parallel execution.


### 2. Core Pattern: Adapting for the Scheduler

The `scheduler.all` and `scheduler.allSettled` functions are designed to execute an array of `Task<C, V, R>` instances, where each task in the array receives the *same common input value `V`*.

However, for `mapReduce`, `filter`, and `groupBy`, we want to apply an operation (map, predicate, keying function) to *each individual item* in an input data array. Each item is distinct.

To bridge this, these utilities follow a common internal pattern:

1.  Take an input data array (e.g., `data: TItem[]`).
2.  Take a per-item operation (e.g., `mapTaskForItem: Task<C, TItem, RMapped>`).
3.  For each `item` in `data`, create a *new, item-specific task*. This new task is typically `Task<C, null, RMapped>` because the specific `item` is captured in its closure. It expects a dummy input (like `null`) because its primary data (`item`) is already bound.
    ```typescript
    // Inside mapReduce, for example:
    const itemProcessingTasks = data.map((item, index) => {
      const itemSpecificMapTask: Task<C, null, RMapped> = 
        (ctx: C, _dummyInput: null) => mapTaskForItem(ctx, item); // `item` is closed over
      return itemSpecificMapTask;
    });
    ```
4.  This array of `itemProcessingTasks` (all of type `Task<C, null, SomeResult>`) is then passed to `scheduler.all` or `scheduler.allSettled` with `null` as the common input value.

This adaptation allows the generic scheduler to process item-specific operations in parallel.


### 3. API Reference & Usage

#### `mapReduce`

Performs a parallel map over an array, then a sequential reduce.

**Signature:**
`mapReduce<C, TItem, RMapped, UAccumulator>(data: TItem[], options: MapReduceOptions<...>): Task<C, null, UAccumulator>`

**`MapReduceOptions<C, TItem, RMapped, UAccumulator>` Interface:**
(Extends `ParallelOptions` from `scheduler.ts`)

| Property | Type                                                                                             | Description                                                                 |
| :------- | :----------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------- |
| `map`    | `Task<C, TItem, RMapped>`                                                                        | The `Task` to apply to each `TItem` in `data` during the parallel map phase. |
| `reduce` | `(acc: UAccumulator, current: RMapped, index: number, all: RMapped[]) => UAccumulator`          | Synchronous reducer function, like `Array.prototype.reduce`.                |
| `initial`| `UAccumulator`                                                                                   | Initial value for the accumulator in the reduce phase.                      |
| `...ParallelOptions` | (optional)                                                                       | Options like `concurrency`, `priority` for the parallel map phase.          |

**Returns:** A `Task` that takes `null` as input (as `data` is already provided) and resolves to the final `UAccumulator` value.

**Behavior:**
*   The `map` tasks run in parallel.
*   Uses `scheduler.all` internally for the map phase, so it's **fail-fast**: if any `map` task rejects, the entire `mapReduce` task rejects.
*   `preserveOrder: true` is enforced for the map phase to ensure results are reduced in a predictable order.

**Example:**
```typescript
// import { mapReduce, defineTask, run, createContext, type BaseContext } from 'effectively';
// import type { ParallelOptions } from 'path/to/scheduler'; // If needed for options

// interface MyContext extends BaseContext { /* ... */ }
// const { run: appRun, defineTask: appDefineTask } = createContext<MyContext>({ /* ... */ });

// const productIds = ["p1", "p2", "p3", "p4", "p5"];
// const fetchPrice = appDefineTask(async (ctx, productId: string): Promise<number> => {
//   // Simulate API call
//   await new Promise(res => setTimeout(res, Math.random() * 100));
//   if (productId === "p3") throw new Error(`Price unavailable for ${productId}`);
//   return 10 + Math.random() * 5; // Random price
// });

// const sumAllPrices = mapReduce(productIds, {
//   map: fetchPrice,
//   reduce: (total, price) => total + price,
//   initial: 0,
//   concurrency: 3
// });

// async function main() {
//   try {
//     const totalPrice = await appRun(sumAllPrices, null);
//     console.log("Total price of products:", totalPrice);
//   } catch (error) {
//     console.error("MapReduce failed:", error); // Will catch if p3 fails
//   }
// }
// main();
```

#### `filter` (Pipeable Operator)

Filters an array by applying an asynchronous predicate `Task` to each item in parallel.

**Signature:**
`filter<C, VItem>(predicateTaskForItem: Task<C, VItem, boolean>, options?: ParallelOptions): Task<C, VItem[], VItem[]>`

**Parameters:**

*   `predicateTaskForItem: Task<C, VItem, boolean>`: A task that takes an item (`VItem`) and returns a `Promise<boolean>`.
*   `options?: ParallelOptions`: Optional concurrency settings for running predicate tasks.

**Returns:** A `Task` that takes an array `VItem[]` as input and resolves to a new filtered `VItem[]`.

**Behavior:**
*   Predicate tasks run in parallel.
*   Uses `scheduler.allSettled` internally for predicate evaluation to ensure all predicates are attempted.
*   **Error Handling:** If a `predicateTaskForItem` *itself* rejects (throws an error instead of resolving to `true`/`false`), the `filter` task will re-throw this error, wrapped in a generic `Error`. This highlights unexpected issues in your predicate logic. Items for which the predicate fails in this way are effectively excluded.
*   `preserveOrder: true` is enforced for predicate results to correctly match them back to original data items.

**Example (as a pipeable operator):**

```typescript
// import { filter, createWorkflow, fromValue, map, defineTask, run, ... } from 'effectively';
// interface User { id: string; isActive: boolean; lastLogin?: Date; }
// const users: User[] = [
//   { id: '1', isActive: true, lastLogin: new Date(Date.now() - 10000) },
//   { id: '2', isActive: false },
//   { id: '3', isActive: true, lastLogin: new Date(Date.now() - 90000000) }, // Stale login
// ];

// const checkRecentLogin = appDefineTask(async (ctx, user: User): Promise<boolean> => {
//   if (!user.isActive || !user.lastLogin) return false;
//   // Simulate an async check, e.g., against an audit service
//   await new Promise(res => setTimeout(res, 50));
//   const oneDayAgo = Date.now() - (24 * 60 * 60 * 1000);
//   return user.lastLogin.getTime() > oneDayAgo;
// });

// const getRecentlyActiveUsers = createWorkflow(
//   fromValue(users),
//   filter(checkRecentLogin, { concurrency: 2 }),
//   map(activeUsers => activeUsers.map(u => u.id))
// );

// async function main() {
//   const recentlyActiveUserIds = await appRun(getRecentlyActiveUsers, undefined);
//   console.log("Recently active user IDs:", recentlyActiveUserIds); // e.g., ['1']
// }
// main();
```

---

#### `groupBy` (Pipeable Operator)

Groups items from an array into a `Map` based on a key. The key for each item is generated by applying a `keyingTaskOrFn` in parallel.

**Signature:**
`groupBy<C, VItem, KKey extends string | number | symbol>(keyingTaskOrFn: Task<C, VItem, KKey> | ((item: VItem) => KKey), options?: ParallelOptions): Task<C, VItem[], Map<KKey, VItem[]>>`

**Parameters:**

*   `keyingTaskOrFn: Task<C, VItem, KKey> | ((item: VItem) => KKey)`:
    *   Either a `Task` that takes an item (`VItem`) and resolves to its key (`KKey`).
    *   Or a synchronous function `(item: VItem) => KKey`. If a plain function is provided, it's wrapped into a `Task` using the global `defineTask` (it won't receive context directly; use a full `Task` if context is needed for keying).
*   `options?: ParallelOptions`: Optional concurrency settings for running keying tasks.

**Returns:** A `Task` that takes an array `VItem[]` as input and resolves to a `Map<KKey, VItem[]>`.

**Behavior:**
*   Keying tasks/functions run in parallel.
*   Uses `scheduler.all` internally for key generation, so it's **fail-fast**: if any keying operation rejects, the entire `groupBy` task rejects.
*   `preserveOrder: true` is enforced for key generation to correctly associate keys with original data items.

**Example (as a pipeable operator):**

```typescript
// import { groupBy, createWorkflow, fromValue, map, defineTask, run, ... } from 'effectively';
// interface Product { id: string; category: string; price: number; }
// const products: Product[] = [
//   { id: '1', category: 'electronics', price: 100 },
//   { id: '2', category: 'books', price: 20 },
//   { id: '3', category: 'electronics', price: 150 },
// ];

// const getProductCategory = (item: Product) => item.category; // Sync keying function

// const groupProducts = createWorkflow(
//   fromValue(products),
//   groupBy(getProductCategory, { concurrency: 3 }), // Can also pass an async Task here
//   map(groupedMap => {
//     const summary: Record<string, number> = {};
//     for (const [category, items] of groupedMap.entries()) {
//       summary[category] = items.length;
//     }
//     return summary;
//   })
// );

// async function main() {
//   const categoryCounts = await appRun(groupProducts, undefined);
//   console.log("Products by category:", categoryCounts); // { electronics: 2, books: 1 }
// }
// main();
```

### 4. Key Concepts & How They Work

*   **Interaction with Scheduler:** These utilities adapt your per-item operations into a format suitable for `scheduler.all` or `scheduler.allSettled`. They create an array of new, temporary tasks, each bound to a specific item from your input data. This array of temporary tasks (which expect a dummy `null` input) is then executed by the scheduler.
*   **Context Handling:** The `context` active when `mapReduce`, `filter`, or `groupBy` is run is captured and passed to each per-item task (`map`, `predicate`, or `keying` task). If these per-item tasks were defined using the global `defineTask` and use `getContext()`, they will correctly resolve to this captured context due to your library's smart context propagation.
*   **Error Propagation:**
    *   `mapReduce` and `groupBy` are fail-fast for their parallel phase (map and keying, respectively) because they use `scheduler.all`. If any item's map/keying task fails, the whole operation fails.
    *   `filter` uses `scheduler.allSettled` for its predicate tasks. If a predicate task *itself* throws an error (rather than returning `true`/`false`), `filter` will detect this rejection and re-throw it, as a predicate failing is usually an unexpected issue.
*   **Concurrency and `ParallelOptions`:** The `ParallelOptions` (like `concurrency`, `priority`) you provide are passed down to the underlying `scheduler.all` or `scheduler.allSettled` call, controlling how the item-specific tasks are executed.

### 5. Usage Examples

*(See examples under each API function above for specific use cases.)*

**General Pattern for `filter` and `groupBy` (as Pipeable Operators):**

```typescript
// import { createWorkflow, fromValue, filter, groupBy, map, ... } from 'effectively/utils'; // And this module

// const processingPipeline = createWorkflow(
//   fromValue(initialArrayData),
//   filter(someAsyncPredicateTask, { concurrency: 4 }),
//   groupBy(someAsyncKeyingTask, { concurrency: 2 }),
//   map(groupedData => {
//     // Process the Map<Key, FilteredItem[]>
//     return /* final result */;
//   })
// );
// const finalOutput = await appRun(processingPipeline, undefined);
```

**General Pattern for `mapReduce` (Standalone Task):**

```typescript
// const dataToProcess = [/* ... */];
// const perItemMapTask = appDefineTask(async (ctx, item) => { /* ... return mappedItem ... */ });
// const reduceResults = (accumulator, mappedItem) => { /* ... return newAccumulator ... */ };

// const mapReduceOperation = mapReduce(dataToProcess, {
//   map: perItemMapTask,
//   reduce: reduceResults,
//   initial: initialAccumulatorValue,
//   concurrency: 5
// });

// // mapReduceOperation is Task<C, null, UAccumulator>
// const finalAggregatedValue = await appRun(mapReduceOperation, null);
```

### 6. Best Practices & Considerations

*   **Task Granularity:** The per-item tasks (for map, filter, group) should represent a reasonable unit of work. Very tiny synchronous operations might not benefit much from parallelization due to overhead.
*   **Fail-Fast vs. Settled:**
    *   Use `mapReduce` or `groupBy` (which use `scheduler.all` internally) if a failure in any single item's processing should halt the entire operation.
    *   For `filter`, predicates failing unexpectedly (not just returning `false`) will cause the filter to fail. Consider if your predicates should use `attempt` internally if they might throw recoverable errors but still need to produce a boolean.
*   **Concurrency:** Choose `concurrency` levels carefully based on the nature of the per-item tasks (CPU-bound vs. I/O-bound) and external system limits (see [Scheduler Guide](#9-best-practices--performance-considerations) from the parallel execution docs).
*   **Normalization in `groupBy`:** If you provide a plain synchronous function to `groupBy` for keying, it's wrapped by the global `defineTask`. If this keying function needs context, define it as a full `Task<C, VItem, KKey>` yourself and pass that.
*   **Error Messages in `filter`:** The `filter` utility logs an error to the console and then re-throws if a predicate task rejects. You might want to customize this behavior if predicates are expected to sometimes fail operationally.


### 7. Troubleshooting

*   **Type Errors with `Task` Arguments:** Ensure the `map`, `predicateTask`, and `keyingTaskOrFn` you provide have signatures compatible with `Task<C, TItem, YourResult>`. The `TItem` is the type of elements in your input data array.
*   **`mapReduce` or `groupBy` Failing Unexpectedly:** Since these are fail-fast for their parallel phases, a single failing `map` or `keying` task will cause the entire operation to reject. Isolate and test the per-item task with problematic data.
*   **`filter` Predicate Errors:** If `filter` throws "Predicate error during filter...", check your predicate task. It should robustly return `true` or `false`, or if it can throw, consider wrapping it with `attempt` (from `@doeixd/effectively/utils`) and then mapping the `Result<boolean, Error>` to a plain `boolean` (e.g., treating errors as `false`).
*   **Performance Issues:**
    *   Adjust `concurrency`. Too high can cause thrashing; too low underutilizes resources.
    *   If per-item tasks are very small, the overhead of parallelism might negate benefits. Consider if the operations truly benefit from being `Task`s or if simpler synchronous array methods suffice.
    *   Check the performance of the underlying `scheduler.all` and `scheduler.allSettled` if issues persist.
